#!/usr/bin/env python3

# Copyright (c) 2025, NVIDIA CORPORATION. All rights reserved.
# 
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions
# are met:
#  * Redistributions of source code must retain the above copyright
#    notice, this list of conditions and the following disclaimer.
#  * Redistributions in binary form must reproduce the above copyright
#    notice, this list of conditions and the following disclaimer in the
#    documentation and/or other materials provided with the distribution.
#  * Neither the name of NVIDIA CORPORATION nor the names of its
#    contributors may be used to endorse or promote products derived
#    from this software without specific prior written permission.
# 
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
# EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
# PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
# CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
# EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
# PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
# OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

"""
Convert raw CPU prefill benchmark results (JSON) into an Excel workbook
compatible with the plotting utilities in *prefilltokens*.  The script scans
<project-root>/cpu_raw/prefill/ for result JSON files generated by the
`token2metrics` evaluation pipeline and aggregates the following per-question
metrics:

• input_tokens
• ttft              – time to first token in **milliseconds** (kept identical to
                      Jetson XLSX so downstream code can divide by 1000)
• time_ms           – full latency (in milliseconds)
• tokens_per_second – throughput (question-level)
• subject           – MMLU/bench subject the question belongs to
• question_id       – original question id (int)

A separate worksheet is created for every model (worksheet name matching the
GPU XLSX, e.g. `DeepSeek-R1-Distill-Qwen-1_5B`).  This means the *dot* in
`1.5B` is replaced by an underscore so the existing Figure 2 scripts work
unchanged.

Usage
-----
python cpu_prefill_processing.py \
    --raw-dir cpu_raw/prefill \
    --out datasets/cpu_prefill/processed_results/all_results_by_model_cpu.xlsx

You can omit both arguments – sensible defaults are chosen.

The script purposefully keeps dependencies minimal (Std-lib + pandas).
"""
from __future__ import annotations

import argparse
import json
from pathlib import Path
from typing import Iterable, Dict, List

import pandas as pd

# ---------------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------------

def _iter_result_jsons(base_dir: Path) -> Iterable[Path]:
    """Yield all JSON result files under *base_dir*."""
    return base_dir.rglob("results_*.json")


def _normalise_model_dir_name(model_dir: str) -> str:
    """Make model dir (which may contain '.') compatible with XLSX sheet name.
    GPU sheets use 1_5B, 8B, 14B etc.  We therefore just replace the final
    numeric part's dot with an underscore (only affects 1.5B).
    """
    if "1.5B" in model_dir:
        return model_dir.replace("1.5B", "1_5B")
    return model_dir


# ---------------------------------------------------------------------------
# Aggregation
# ---------------------------------------------------------------------------

def collect_prefill_records(json_path: Path) -> List[Dict]:
    """Read *json_path* and return a list of records (dicts) for each question."""
    with json_path.open("r", encoding="utf-8") as fp:
        data = json.load(fp)

    subject = data.get("subject", "unknown")
    model_name = data.get("model_name", "unknown")

    records: List[Dict] = []
    for q in data.get("question_results", []):
        records.append({
            "input_tokens": q.get("input_tokens", None),
            "ttft": q.get("ttft", None),            # milliseconds
            "time_ms": q.get("time_ms", None),
            "tokens_per_second": q.get("tokens_per_second", None),
            "subject": subject,
            "question_id": q.get("question_id", None),
            # Will group by this later
            "model_name": model_name,
        })
    return records


def build_dataframe(raw_dir: Path) -> pd.DataFrame:
    """Aggregate all JSON under *raw_dir* into a single DataFrame."""
    all_records: List[Dict] = []
    json_files = list(_iter_result_jsons(raw_dir))
    if not json_files:
        raise FileNotFoundError(f"No JSON files found under {raw_dir}")

    print(f"Found {len(json_files)} JSON result files – parsing…")
    for jp in json_files:
        try:
            all_records.extend(collect_prefill_records(jp))
        except Exception as exc:
            print(f"  [WARN] Skipping {jp.relative_to(raw_dir)}: {exc}")
    df = pd.DataFrame(all_records)
    # Drop rows with missing critical values
    df = df.dropna(subset=["input_tokens", "ttft"])
    df["input_tokens"] = df["input_tokens"].astype(int)
    df["ttft"] = df["ttft"].astype(float)
    return df


# ---------------------------------------------------------------------------
# Excel writer
# ---------------------------------------------------------------------------

def write_per_model_excel(df: pd.DataFrame, out_path: Path) -> None:
    """Save *df* into *out_path* with one sheet per model."""
    out_path.parent.mkdir(parents=True, exist_ok=True)
    with pd.ExcelWriter(out_path, engine="openpyxl") as writer:
        for model, sub_df in df.groupby("model_name"):
            sheet_name = _normalise_model_dir_name(model)
            # Safety: Excel sheet names max 31 chars, no '/' or '\\'
            sheet_name = sheet_name.replace("/", "_").replace("\\", "_")
            sheet_name = sheet_name[:31]
            cols_order = [
                "input_tokens",
                "ttft",
                "time_ms",
                "tokens_per_second",
                "subject",
                "question_id",
            ]
            sub_df[cols_order].to_excel(writer, sheet_name=sheet_name, index=False)
    print(f"Saved aggregated results to: {out_path}")


# ---------------------------------------------------------------------------
# CLI
# ---------------------------------------------------------------------------

def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="CPU prefill result aggregator")
    parser.add_argument(
        "--raw-dir",
        type=Path,
        default=Path("cpu_raw/prefill"),
        help="Directory containing raw prefill result JSONs (default: cpu_raw/prefill)",
    )
    parser.add_argument(
        "--out",
        type=Path,
        default=Path("datasets/cpu_prefill/processed_results/all_results_by_model_cpu.xlsx"),
        help="Path where the Excel workbook will be written.",
    )
    return parser.parse_args()


def main() -> None:
    args = parse_args()
    df = build_dataframe(args.raw_dir)
    write_per_model_excel(df, args.out)


if __name__ == "__main__":
    main()
